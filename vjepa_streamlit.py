# Streamlit app using V-JEPA for feature extraction + overall best classifier

import streamlit as st
import torch
from transformers import AutoModel, AutoVideoProcessor
import torchvision.io as io
import os
import tempfile
import subprocess
import joblib # å°å…¥ joblib
import numpy as np

# --- Streamlit é é¢é…ç½® ---
st.set_page_config(page_title="V-JEPA Video Classifier", layout="centered")

st.title("ğŸ¬ V-JEPA 2 + å½±ç‰‡åˆ†é¡å™¨")
st.write("ä¸Šå‚³å½±ç‰‡ï¼Œè‡ªå‹•è½‰æˆ MP4ï¼ŒæŠ½å–ç‰¹å¾µä¸¦ç”¨**è¨“ç·´å¾Œæ•´é«”æœ€ä½³æ¨¡å‹**é€²è¡Œåˆ†é¡ã€‚")

# --- è¼‰å…¥ label_map.txt çš„å‡½æ•¸ ---
def load_label_map(path="label_map.txt"):
    mapping = {}
    try:
        with open(path, "r") as f:
            for line in f:
                idx, label = line.strip().split()
                mapping[int(idx)] = label
    except FileNotFoundError:
        st.error("âŒ æ‰¾ä¸åˆ° `label_map.txt`ï¼Œè«‹å…ˆåŸ·è¡Œè¨“ç·´è…³æœ¬ä»¥ç”Ÿæˆè©²æª”æ¡ˆã€‚")
        return None
    return mapping

label_map = load_label_map()
if label_map is None:
    st.stop() # å¦‚æœæ²’æœ‰ label_mapï¼Œåœæ­¢æ‡‰ç”¨ç¨‹å¼

# --- è¼‰å…¥ V-JEPA å’Œåˆ†é¡å™¨æ¨¡å‹ ---
@st.cache_resource # ä½¿ç”¨ Streamlit çš„å¿«å–ï¼Œé¿å…æ¯æ¬¡åŸ·è¡Œéƒ½é‡æ–°è¼‰å…¥å¤§æ¨¡å‹
def load_models():
    hf_repo = "facebook/vjepa2-vitg-fpc64-256"
    
    st.write("â³ è¼‰å…¥ V-JEPA ç‰¹å¾µæå–æ¨¡å‹ä¸­...")
    processor = AutoVideoProcessor.from_pretrained(hf_repo)
    base_model = AutoModel.from_pretrained(hf_repo)
    base_model.cuda().eval() # å°‡æ¨¡å‹ç§»åˆ° GPU ä¸¦è¨­ç‚ºè©•ä¼°æ¨¡å¼

    st.write("â³ è¼‰å…¥è¨“ç·´å¾Œ**æ•´é«”æœ€ä½³**åˆ†é¡å™¨æ¨¡å‹ (`vjepa_classifier_overall_best.pt`) ä¸­...")
    try:
        # **é€™è£¡å°±æ˜¯é—œéµçš„ä¿®æ”¹ï¼** è¼‰å…¥æ•´é«”æœ€ä½³æ¨¡å‹
        classifier_model = joblib.load("vjepa_classifier_overall_best.pt")
        st.success("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼")
    except FileNotFoundError:
        st.error("âŒ æ‰¾ä¸åˆ° `vjepa_classifier_overall_best.pt` æ¨¡å‹æª”æ¡ˆã€‚è«‹ç¢ºèªæ‚¨å·²é‹è¡Œè¨“ç·´è…³æœ¬ä¸¦ç”Ÿæˆè©²æª”æ¡ˆã€‚")
        return None, None, None
    except Exception as e:
        st.error(f"âŒ è¼‰å…¥åˆ†é¡å™¨æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None, None, None
        
    return processor, base_model, classifier_model

processor, base_model, classifier_model = load_models()

# å¦‚æœæ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œå‰‡åœæ­¢æ‡‰ç”¨ç¨‹å¼
if classifier_model is None:
    st.stop()

# --- è¦–è¨Šè½‰ MP4 å‡½æ•¸ ---
# Streamlit åœ¨æŸäº›ç’°å¢ƒä¸‹å°æ–¼é MP4 æ ¼å¼æ”¯æ´ä¸å¥½ï¼Œè½‰æª”æ˜¯å€‹å¥½ç¿’æ…£
def convert_to_mp4(input_path):
    output_path = tempfile.mktemp(suffix=".mp4")
    # ä½¿ç”¨ ffmpeg é€²è¡Œè½‰ç¢¼ï¼Œç¢ºä¿è¼¸å‡ºå½±ç‰‡çš„ç·¨ç¢¼å’Œæ ¼å¼å…¼å®¹æ€§
    command = [
        "ffmpeg", "-y", "-i", input_path,
        "-c:v", "libx264", "-preset", "fast", "-crf", "23",
        "-c:a", "aac", "-b:a", "128k", "-movflags", "+faststart", output_path
    ]
    try:
        # ä½¿ç”¨ st.empty() å’Œ progress æ¢é¡¯ç¤ºè½‰æª”é€²åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        # ç°¡æ˜“é€²åº¦æ¢ (å¯èƒ½ä¸ç²¾ç¢ºï¼Œä½†æä¾›ä½¿ç”¨è€…åé¥‹)
        total_duration = 10 # å‡è¨­æœ€é•·è½‰æª”æ™‚é–“ç‚º 10 ç§’ï¼Œç”¨æ–¼é€²åº¦æ¢ç²—ç•¥ä¼°è¨ˆ
        for i in range(1, 101):
            progress_bar.progress(i)
            status_text.text(f"ğŸ¥ å½±ç‰‡è½‰æª”ä¸­... {i}%")
            # å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œå¯ä»¥è§£æ ffmpeg çš„ stderr è¼¸å‡ºä»¥ç²å–æ›´ç²¾ç¢ºçš„é€²åº¦
            # ä½†é€™æœƒä½¿ä»£ç¢¼æ›´è¤‡é›œï¼Œé€™è£¡åªç‚º Streamlit æ¼”ç¤ºä¸€å€‹ç°¡å–®çš„é€²åº¦æ¢
            if i % 20 == 0:
                torch.cuda.empty_cache() # å˜—è©¦é‡‹æ”¾ GPU è¨˜æ†¶é«”

        stdout, stderr = process.communicate(timeout=600) # è¨­å®šè¶…æ™‚
        if process.returncode != 0:
            st.error(f"âŒ å½±ç‰‡è½‰æª”å¤±æ•— (ffmpeg éŒ¯èª¤ç¢¼: {process.returncode}):\n{stderr.decode()}")
            return None
        st.success("âœ… å½±ç‰‡è½‰æª”å®Œæˆï¼")
        return output_path
    except subprocess.CalledProcessError as e:
        st.error(f"âŒ å½±ç‰‡è½‰æª”å¤±æ•—: {e.stderr.decode()}")
        return None
    except subprocess.TimeoutExpired:
        process.kill()
        st.error("âŒ å½±ç‰‡è½‰æª”è¶…æ™‚ï¼Œè«‹æª¢æŸ¥å½±ç‰‡æª”æ¡ˆæˆ–å˜—è©¦è¼ƒçŸ­çš„å½±ç‰‡ã€‚")
        return None
    except Exception as e:
        st.error(f"âŒ å½±ç‰‡è½‰æª”æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {str(e)}")
        return None
    finally:
        # æ¸…é™¤é€²åº¦æ¢å’Œç‹€æ…‹æ–‡æœ¬
        progress_bar.empty()
        status_text.empty()


# --- æŠ½å–ç‰¹å¾µå‡½æ•¸ ---
@torch.no_grad() # ç¢ºä¿ä¸è¨ˆç®—æ¢¯åº¦ï¼Œç¯€çœè¨˜æ†¶é«”
def extract_features(video_tensor):
    # å°‡å½±ç‰‡å¹€ç§»å‹•åˆ° CUDA è¨­å‚™
    # video_tensor çš„å½¢ç‹€å¯èƒ½æ˜¯ (T, H, W, C)ï¼Œéœ€è¦è½‰æ›ç‚ºè™•ç†å™¨æœŸæœ›çš„æ ¼å¼ (ä¾‹å¦‚åˆ—è¡¨ of numpy arrays)
    # æˆ–è€…å¦‚æœ processor èƒ½ç›´æ¥è™•ç† torch.Tensorï¼Œç¢ºä¿å…¶åœ¨ CPU æˆ– GPU ä¸Š
    
    # é€™è£¡æˆ‘å€‘å‡è¨­ processor.preprocess èƒ½å¤ è™•ç† list of numpy arrays (H,W,C)
    # å› æ­¤éœ€è¦å°‡ torch.Tensor (T, H, W, C) è½‰æ›ç‚º list of numpy arrays
    clip_list = [frame.cpu().numpy() for frame in video_tensor]
    
    inputs = processor(clip_list, return_tensors="pt")
    # å°‡è™•ç†å¾Œçš„è¼¸å…¥ç§»å‹•åˆ° CUDA è¨­å‚™
    inputs = {k: v.cuda() for k, v in inputs.items()}
    
    base_output = base_model(**inputs)
    features = base_output.last_hidden_state # (batch_size, sequence_length, hidden_size)
    
    # å°åºåˆ—ç¶­åº¦é€²è¡Œå¹³å‡æ± åŒ–ï¼Œå¾—åˆ°å›ºå®šå¤§å°çš„ç‰¹å¾µå‘é‡ (batch_size, hidden_size)
    # Permute å¾ (B, S, H) åˆ° (B, H, S) ä»¥é©æ‡‰ AdaptiveAvgPool1d
    pooled = torch.nn.functional.adaptive_avg_pool1d(features.permute(0, 2, 1), 1).squeeze(-1)
    
    # è¿”å›ç‰¹å¾µï¼Œç¢ºä¿æ˜¯ CPU ä¸Šçš„ numpy é™£åˆ—ï¼Œä¸”å½¢ç‹€é©åˆ Scikit-learn æ¨¡å‹ (1, feature_dim)
    return pooled.cpu().numpy().reshape(1, -1) # ç¢ºä¿æ˜¯ 2D array for predict


# --- æ¨è«–æµç¨‹ ---
def predict_video(video_path):
    frames_per_clip = 16 # V-JEPA æ¨¡å‹é€šå¸¸æœƒæœŸæœ›å›ºå®šæ•¸é‡çš„å¹€
    
    st.write("ğŸ” è®€å–å½±ç‰‡ä¸¦æº–å‚™ç‰¹å¾µæå–...")
    try:
        # io.read_video è¿”å› (num_frames, H, W, C), pts, meta
        video_tensor, _, _ = io.read_video(video_path, pts_unit='sec')
        
        # ç¢ºä¿å½±ç‰‡å¹€æ•¸è‡³å°‘ç‚º 1
        if video_tensor.shape[0] == 0:
            st.error("âŒ å½±ç‰‡æ²’æœ‰ä»»ä½•å¯è®€å–çš„å¹€ï¼Œè«‹æª¢æŸ¥å½±ç‰‡æª”æ¡ˆæ˜¯å¦æå£ã€‚")
            return "Error"

        # å¦‚æœå½±ç‰‡å¹€æ•¸å°‘æ–¼ `frames_per_clip`ï¼Œå‰‡é€²è¡Œå¡«å……
        if video_tensor.shape[0] < frames_per_clip:
            st.warning(f"å½±ç‰‡å¹€æ•¸ ({video_tensor.shape[0]}) å°‘æ–¼æ¨¡å‹æ‰€éœ€ ({frames_per_clip})ï¼Œå°‡é€²è¡Œå¹€å¡«å……ã€‚")
            pad_amount = frames_per_clip - video_tensor.shape[0]
            # é‡è¤‡æœ€å¾Œä¸€å¹€é€²è¡Œå¡«å……
            clip = torch.cat([video_tensor, video_tensor[-1:].repeat(pad_amount, 1, 1, 1)])
        else:
            # å¦‚æœå½±ç‰‡å¹€æ•¸éå¤šï¼Œå‰‡å¾ä¸­é–“æˆªå– `frames_per_clip` å¹€
            start = (video_tensor.shape[0] - frames_per_clip) // 2
            clip = video_tensor[start : start + frames_per_clip]
        
        # ç¢ºä¿ clip å·²ç¶“åœ¨ CPU ä¸Šï¼Œå› ç‚º extract_features æœƒè™•ç†åˆ° GPU
        clip = clip.cpu()

        st.write("ğŸš€ æŠ½å–å½±ç‰‡ç‰¹å¾µä¸­...")
        feature = extract_features(clip) # æå–ç‰¹å¾µ

        st.write("ğŸ§  é€²è¡Œåˆ†é¡é æ¸¬...")
        # åˆ†é¡æ¨¡å‹é€šå¸¸æœŸæœ› 2D æ•¸çµ„ (n_samples, n_features)
        # feature å·²ç¶“è¢« reshape æˆ (1, feature_dim)
        pred_id = classifier_model.predict(feature)[0]
        
        predicted_label = label_map.get(pred_id, "æœªçŸ¥é¡åˆ¥")
        
        # å¦‚æœåˆ†é¡å™¨æ”¯æŒ predict_probaï¼Œå‰‡é¡¯ç¤ºæ©Ÿç‡
        if hasattr(classifier_model, 'predict_proba'):
            probabilities = classifier_model.predict_proba(feature)[0]
            st.write("å„é¡åˆ¥é æ¸¬æ©Ÿç‡:")
            prob_dict = {label_map[i]: f"{prob:.2%}" for i, prob in enumerate(probabilities)}
            st.json(prob_dict)

        return predicted_label

    except Exception as e:
        st.error(f"æ¨è«–æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        # æ›´è©³ç´°çš„éŒ¯èª¤æ—¥èªŒå¯ä»¥åœ¨å¾Œç«¯æŸ¥çœ‹
        print(f"DEBUG: Error during prediction: {e}", exc_info=True)
        return "Error"

# --- Streamlit UI é‚è¼¯ ---
uploaded_file = st.file_uploader("è«‹ä¸Šå‚³å½±ç‰‡æª”ï¼ˆavi, mp4, mov, mkv, flvï¼‰", type=["avi", "mp4", "mov", "mkv", "flv"])

if uploaded_file is not None:
    # ä½¿ç”¨ tempfile è™•ç†ä¸Šå‚³æª”æ¡ˆï¼Œç¢ºä¿è·¨å¹³å°å…¼å®¹æ€§
    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[-1]) as tmp_file:
        tmp_file.write(uploaded_file.read())
        uploaded_video_path = tmp_file.name

    st.video(uploaded_video_path) # é¡¯ç¤ºåŸå§‹ä¸Šå‚³å½±ç‰‡

    # ç¢ºä¿æ˜¯ MP4 æ ¼å¼ï¼Œffmpeg æœƒå°‡å½±ç‰‡è½‰ç¢¼ç‚º MP4
    mp4_video_path = convert_to_mp4(uploaded_video_path)
    
    # åˆªé™¤è‡¨æ™‚ä¸Šå‚³çš„åŸå§‹æª”æ¡ˆ
    os.unlink(uploaded_video_path)

    if mp4_video_path:
        with st.spinner("âœ¨ æ­£åœ¨ä½¿ç”¨æœ€ä½³æ¨¡å‹é€²è¡Œé æ¸¬..."):
            predicted_label = predict_video(mp4_video_path)
            
        if predicted_label != "Error":
            st.success(f"âœ… é æ¸¬çµæœï¼šé€™å€‹å½±ç‰‡çš„æ´»å‹•æ˜¯ **{predicted_label}**ï¼")
        
        # é æ¸¬å®Œæˆå¾Œåˆªé™¤è‡¨æ™‚çš„ MP4 æª”æ¡ˆ
        if os.path.exists(mp4_video_path):
            os.unlink(mp4_video_path)